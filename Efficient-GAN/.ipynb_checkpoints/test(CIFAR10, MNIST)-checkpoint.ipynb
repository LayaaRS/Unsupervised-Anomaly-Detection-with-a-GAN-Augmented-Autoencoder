{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from imp import reload\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "beta1 = 0.5\n",
    "beta2 = 1e-4\n",
    "num_epochs = 500\n",
    "latent_size_CIFAR10 = 100\n",
    "latent_size_MNIST = 200\n",
    "acc_lam = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_CIFAR10 = torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "transform_CIFAR10 = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                                    torchvision.transforms.RandomVerticalFlip(),\n",
    "                                                    torchvision.transforms.ToTensor(),\n",
    "                                                    normalize_CIFAR10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CIFAR10 = torchvision.datasets.CIFAR10('./data/CIFAR10/', train=True, \n",
    "                                            transform=transform_CIFAR10, target_transform=None, download=False)\n",
    "test_CIFAR10 = torchvision.datasets.CIFAR10('./data/CIFAR10/', train=False, \n",
    "                                            transform=transform_CIFAR10, target_transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.tensor(train_CIFAR10.targets) == torch.tensor(0)\n",
    "dset_train = torch.utils.data.dataset.Subset(train_CIFAR10, np.where(idx==True)[0])\n",
    "dset_train_anomalous = torch.utils.data.dataset.Subset(train_CIFAR10, np.where(idx==False)[0])\n",
    "trainloader = torch.utils.data.DataLoader(dset_train, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = torch.tensor(test_CIFAR10.targets) == torch.tensor(0)\n",
    "dset_test = torch.utils.data.dataset.Subset(test_CIFAR10, np.where(idx==True)[0])\n",
    "dset_test_anomalous = torch.utils.data.dataset.Subset(test_CIFAR10, np.where(idx==False)[0])\n",
    "testloader_normal = torch.utils.data.DataLoader(dset_test, batch_size=1, shuffle=True)\n",
    "testloader_anomalous = torch.utils.data.ConcatDataset([dset_train_anomalous, dset_test_anomalous])\n",
    "testloader_anomalous = torch.utils.data.DataLoader(testloader_anomalous, batch_size=1, shuffle=True)\n",
    "print (len(trainloader))\n",
    "print (len(testloader_normal), len(testloader_anomalous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_criterion = nn.CrossEntropyLoss()\n",
    "aen_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = model.Encoder_CIFAR10(latent_size_CIFAR10, True)\n",
    "gen = model.Generator_CIFAR10(latent_size_CIFAR10)\n",
    "dis = model.Discriminator_CIFAR10(latent_size_CIFAR10, 0.2, 1)\n",
    "dis.to(device);\n",
    "enc.to(device);\n",
    "gen.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.load_state_dict(torch.load('./results/CIFAR10/ALAD_way/9/CIFAR1010epochsGaussian2020-03-17-10-14-07G.pt'))\n",
    "enc.load_state_dict(torch.load('./results/CIFAR10/ALAD_way/9/CIFAR1010epochsGaussian2020-03-17-10-14-07E.pt'))\n",
    "dis.load_state_dict(torch.load('./results/CIFAR10/ALAD_way/9/CIFAR1010epochsGaussian2020-03-17-10-14-07D.pt'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.2\n",
    "loss_neg = torch.zeros((len(testloader_normal),1)).cuda()\n",
    "loss_pos = torch.zeros((len(testloader_anomalous),1)).cuda()\n",
    "c_neg = c_pos = 0\n",
    "for step, (images, labels) in enumerate(testloader_normal, 0):\n",
    "    images = images.view(-1, 3, 32, 32)\n",
    "    dis.eval()\n",
    "    gen.eval()\n",
    "    enc.eval()\n",
    "    x_real_test = images.cuda()\n",
    "    E_x, _, _, _ = enc(x_real_test)\n",
    "    G_z = gen(E_x[:, :100]).detach()\n",
    "    real, internal_real = dis(x_real_test, E_x[:, :100])\n",
    "    fake, internal_fake = dis(G_z, E_x[:, :100])\n",
    "    \n",
    "    resloss = torch.mean(torch.abs(x_real_test - G_z))\n",
    "    discloss = torch.mean(torch.abs(internal_real - internal_fake))\n",
    "    loss_test = ((1 - lam) * resloss + lam * discloss)\n",
    "    loss_neg[c_neg] = loss_test.detach()\n",
    "    c_neg += 1\n",
    "\n",
    "for step, (images, labels) in enumerate(testloader_anomalous, 0):\n",
    "    images = images.view(-1, 3, 32, 32)\n",
    "    dis.eval()\n",
    "    gen.eval()\n",
    "    enc.eval()\n",
    "    x_real_test = images.cuda()\n",
    "    E_x, _, _, _ = enc(x_real_test)\n",
    "    G_z = gen(E_x[:, :100]).detach()\n",
    "    real, internal_real = dis(x_real_test, E_x[:, :100])\n",
    "    fake, internal_fake = dis(G_z, E_x[:, :100])\n",
    "    \n",
    "    resloss = torch.mean(torch.abs(x_real_test - G_z))\n",
    "    discloss = torch.mean(torch.abs(internal_real - internal_fake))\n",
    "    loss_test = ((1 - lam) * resloss + lam * discloss)\n",
    "    loss_pos[c_pos] = loss_test.detach()\n",
    "    c_pos += 1\n",
    "\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = loss_neg.cpu().numpy()\n",
    "x2 = loss_pos.cpu().numpy()\n",
    "sns.distplot(x1, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Normal')\n",
    "sns.distplot(x2, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Anomalous')\n",
    "plt.title('Distribution of normal and abnormal samples')\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Samples');\n",
    "\n",
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 0.50:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 0.50:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[lam] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print ('AUC', auc)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0.0, 1.0], color='navy', linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_MNIST = torchvision.transforms.Normalize((0.5, ), (0.5, ))\n",
    "transform_MNIST = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                                  torchvision.transforms.RandomVerticalFlip(),\n",
    "                                                  torchvision.transforms.ToTensor(), normalize_MNIST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MNIST = torchvision.datasets.MNIST('./data/MNIST/', train=True,\n",
    "                                         transform=transform_MNIST, target_transform=None, download=False)\n",
    "test_MNIST = torchvision.datasets.MNIST('./data/MNIST/', train=False,\n",
    "                                            transform=transform_MNIST, target_transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.as_tensor(train_MNIST.targets) == torch.tensor(9)\n",
    "dset_train = (torch.utils.data.dataset.Subset(train_MNIST, np.where(idx != 0)[0]))\n",
    "dset_train_anomalous = torch.utils.data.dataset.Subset(train_MNIST, np.where(idx == 0)[0])\n",
    "trainloader = torch.utils.data.DataLoader(dset_train, batch_size=1, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.as_tensor(test_MNIST.targets) == torch.tensor(9)\n",
    "dset_test = torch.utils.data.dataset.Subset(test_MNIST, np.where(idx != 0)[0])\n",
    "dset_test_anomalous = torch.utils.data.dataset.Subset(test_MNIST, np.where(idx == 0)[0])\n",
    "testloader_normal = torch.utils.data.DataLoader(dset_test, batch_size=1, drop_last=True, shuffle=True)\n",
    "testloader_anomalous = torch.utils.data.ConcatDataset([dset_train_anomalous, dset_test_anomalous])\n",
    "testloader_anomalous = torch.utils.data.DataLoader(testloader_anomalous, batch_size=1, drop_last=True, shuffle=True)\n",
    "print (len(testloader_normal))\n",
    "print (len(testloader_anomalous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = model.Encoder_MNIST(latent_size_MNIST, True)\n",
    "gen = model.Generator_MNIST(latent_size_MNIST)\n",
    "dis = model.Discriminator_MNIST(latent_size_MNIST, 0.2, 1)\n",
    "dis.to(device);\n",
    "enc.to(device); \n",
    "gen.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.load_state_dict(torch.load('./results/MNIST/ALAD_way/9/MNIST10epochsGaussian2020-03-16-22-31-57G.pt'))\n",
    "enc.load_state_dict(torch.load('./results/MNIST/ALAD_way/9/MNIST10epochsGaussian2020-03-16-22-31-57E.pt'))\n",
    "dis.load_state_dict(torch.load('./results/MNIST/ALAD_way/9/MNIST10epochsGaussian2020-03-16-22-31-57D.pt'));\n",
    "\n",
    "# torch.load('./models/MNIST/Gaussian/9/MNIST10epochs2020-03-04-15-21-14G')\n",
    "# torch.load('./models/MNIST/Gaussian/9/MNIST10epochs2020-03-04-15-21-14E')\n",
    "# torch.load('./models/MNST/Gaussian/9/MNIST10epochs2020-03-04-15-21-14D');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lam = 0.1\n",
    "loss_neg = torch.zeros((len(testloader_normal),1)).cuda()\n",
    "loss_pos = torch.zeros((len(testloader_anomalous),1)).cuda()\n",
    "res_loss = torch.zeros(((len(testloader_normal) + len(testloader_anomalous)),1)).cuda()\n",
    "disc_loss = torch.zeros(((len(testloader_normal) + len(testloader_anomalous)),1)).cuda()\n",
    "res_test_normal = torch.zeros((len(testloader_normal), 1)).cuda()\n",
    "res_test_anomalous = torch.zeros((len(testloader_anomalous), 1)).cuda()\n",
    "dis_test_normal = torch.zeros((len(testloader_normal), 1)).cuda()\n",
    "dis_test_anomalous = torch.zeros((len(testloader_anomalous), 1)).cuda()\n",
    "c_neg = c_pos = 0\n",
    "for step, (images, labels) in enumerate(testloader_normal, 0):\n",
    "#     images = images.view(-1, 1, 28, 28)\n",
    "    dis.eval()\n",
    "    gen.eval()\n",
    "    enc.eval()\n",
    "    x_real_test = images.cuda()\n",
    "    E_x, _, _, _ = enc(x_real_test)\n",
    "    E_x = E_x[:, :200].unsqueeze(2).unsqueeze(3)\n",
    "    G_z = gen(E_x[:, :200]).detach()\n",
    "    real, internal_real = dis(x_real_test, E_x[:, :200])\n",
    "    fake, internal_fake = dis(G_z, E_x[:, :200])\n",
    "\n",
    "    resloss = torch.mean(torch.abs(x_real_test - G_z))\n",
    "    discloss = torch.mean(torch.abs(internal_real - internal_fake))\n",
    "    loss_test = ((1 - lam) * resloss + lam * discloss) \n",
    "    loss_neg[c_neg] = loss_test.detach()\n",
    "    c_neg += 1\n",
    "\n",
    "for step, (images, labels) in enumerate(testloader_anomalous, 0):\n",
    "    dis.eval()\n",
    "    gen.eval()\n",
    "    enc.eval()\n",
    "    x_real_test = images.cuda()\n",
    "    E_x, _, _, _ = enc(x_real_test)\n",
    "    E_x = E_x[:, :200].unsqueeze(2).unsqueeze(3)\n",
    "    G_z = gen(E_x[:, :200]).detach()\n",
    "    real, internal_real = dis(x_real_test, E_x[:, :200, :, :])\n",
    "    fake, internal_fake = dis(G_z, E_x[:, :200, :, :])\n",
    "    \n",
    "    resloss = torch.mean(torch.abs(x_real_test - G_z))\n",
    "    discloss = torch.mean(torch.abs(internal_real - internal_fake))\n",
    "    loss_test = ((1 - lam) * resloss + lam * discloss)\n",
    "    \n",
    "    loss_pos[c_pos] = loss_test.detach()\n",
    "    c_pos += 1\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x1 = loss_neg.cpu().numpy()\n",
    "x2 = loss_pos.cpu().numpy()\n",
    "sns.distplot(x1, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Normal')\n",
    "sns.distplot(x2, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Anomalous')\n",
    "plt.title('Distribution of normal and abnormal samples')\n",
    "plt.xlabel('Anomaly Score');\n",
    "\n",
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 0.70:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 0.70:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[lam] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print ('AUC', auc)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0.0, 1.0], color='navy', linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ids, (images, labels) in enumerate(testloader_anomalous):\n",
    "    print (images[0].shape)\n",
    "    plt.imshow(images[0].squeeze(0), cmap='gray_r')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ids, (images, labels) in enumerate(testloader_normal):\n",
    "    print (images[0].shape)\n",
    "    plt.imshow(images[0].squeeze(0), cmap='gray_r')\n",
    "    plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

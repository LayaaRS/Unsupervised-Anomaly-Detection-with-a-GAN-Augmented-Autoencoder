{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import modules\n",
    "from utils import dataset\n",
    "from imp import reload\n",
    "from modules import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "num_epochs = 10\n",
    "latent_size_CIFAR10 = 100\n",
    "latent_size_MNIST = 200\n",
    "acc_lam = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_CIFAR10 = torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "transform_CIFAR10 = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                                    torchvision.transforms.RandomVerticalFlip(),\n",
    "                                                    torchvision.transforms.ToTensor(),\n",
    "                                                    normalize_CIFAR10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CIFAR10 = torchvision.datasets.CIFAR10('./data/CIFAR10/', train=True, \n",
    "                                            transform=transform_CIFAR10, target_transform=None, download=False)\n",
    "test_CIFAR10 = torchvision.datasets.CIFAR10('./data/CIFAR10/', train=False, \n",
    "                                            transform=transform_CIFAR10, target_transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.tensor(train_CIFAR10.targets) != torch.tensor(0)\n",
    "dset_train = torch.utils.data.dataset.Subset(train_CIFAR10, np.where(idx==True)[0])\n",
    "dset_train_anomalous = torch.utils.data.dataset.Subset(train_CIFAR10, np.where(idx==False)[0])\n",
    "trainloader = torch.utils.data.DataLoader(dset_train, batch_size=1, shuffle=True)\n",
    "print (len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = torch.tensor(test_CIFAR10.targets) != torch.tensor(0)\n",
    "dset_test = torch.utils.data.dataset.Subset(test_CIFAR10, np.where(idx==True)[0])\n",
    "dset_test_anomalous = torch.utils.data.dataset.Subset(test_CIFAR10, np.where(idx==False)[0])\n",
    "testloader_normal = torch.utils.data.DataLoader(dset_test, batch_size=1, shuffle=True)\n",
    "testloader_anomalous = torch.utils.data.ConcatDataset([dset_train_anomalous, dset_test_anomalous])\n",
    "testloader_anomalous = torch.utils.data.DataLoader(testloader_anomalous, batch_size=1, shuffle=True)\n",
    "print (len(trainloader))\n",
    "print (len(testloader_normal), len(testloader_anomalous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_BCElogit_criterion = nn.BCEWithLogitsLoss()\n",
    "dis_criterion = nn.CrossEntropyLoss()\n",
    "aen_criterion = nn.MSELoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = model.Encoder_CIFAR10(latent_size_CIFAR10)\n",
    "gen = model.Generator_CIFAR10(latent_size_CIFAR10)\n",
    "dis_xz = model.Discriminator_xz_CIFAR10(latent_size_CIFAR10, 0.2)\n",
    "dis_xx = model.Discriminator_xx_CIFAR10(latent_size_CIFAR10, 0.2)\n",
    "dis_zz = model.Discriminator_zz_CIFAR10(latent_size_CIFAR10, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.load_state_dict(torch.load('./models/CIFAR10/Gaussian/9/CIFAR1010epochs2020-03-12-19-13-39G'))\n",
    "enc.load_state_dict(torch.load('./models/CIFAR10/Gaussian/9/CIFAR1010epochs2020-03-12-19-13-39E'))\n",
    "dis_xz.load_state_dict(torch.load('./models/CIFAR10/Gaussian/9/CIFAR1010epochs2020-03-12-19-13-39D_xz'))\n",
    "dis_xx.load_state_dict(torch.load('./models/CIFAR10/Gaussian/9/CIFAR1010epochs2020-03-12-19-13-39D_xx'))\n",
    "dis_zz.load_state_dict(torch.load('./models/CIFAR10/Gaussian/9/CIFAR1010epochs2020-03-12-19-13-39D_zz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_xz.to(device)\n",
    "dis_xx.to(device)\n",
    "dis_zz.to(device)\n",
    "enc.to(device)\n",
    "gen.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.1\n",
    "loss_neg = torch.zeros((len(testloader_normal),1)).cuda()\n",
    "loss_pos = torch.zeros((len(testloader_anomalous),1)).cuda()\n",
    "c_neg = c_pos = 0\n",
    "for step, (images, labels) in enumerate(testloader_normal, 0):\n",
    "    images = images.view(-1, 3, 32, 32)\n",
    "    dis_xz.eval()\n",
    "    dis_xx.eval()\n",
    "    dis_zz.eval()\n",
    "    enc.eval()\n",
    "    gen.eval()\n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size_CIFAR10, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "\n",
    "    loss_neg[c_neg] = feature_loss.detach()\n",
    "    c_neg += 1\n",
    "\n",
    "\n",
    "for step, (images, labels) in enumerate(testloader_anomalous, 0):\n",
    "    images = images.view(-1, 3, 32, 32)\n",
    "    dis_xz.eval()\n",
    "    dis_xx.eval()\n",
    "    dis_zz.eval()\n",
    "    enc.eval()\n",
    "    gen.eval()\n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size_CIFAR10, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    loss_pos[c_pos] = feature_loss.detach()\n",
    "    c_pos += 1\n",
    "\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = loss_neg.cpu().numpy()\n",
    "x2 = loss_pos.cpu().numpy()\n",
    "sns.distplot(x1, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Normal')\n",
    "sns.distplot(x2, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Anomalous')\n",
    "plt.title('Distribution of normal and abnormal samples')\n",
    "plt.xlabel('Anomaly Score');\n",
    "\n",
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 120:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 120:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[lam] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "prec, rec, _ = metrics.precision_recall_curve(y.cpu(), scores.cpu())\n",
    "average_precision = metrics.average_precision_score(y.cpu(), scores.cpu())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print ('AUC', auc)\n",
    "print ('average precision :', average_precision)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0.0, 1.0], color='navy', linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_MNIST = torchvision.transforms.Normalize((0.5, ), (0.5, ))\n",
    "transform_MNIST = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                                  torchvision.transforms.RandomVerticalFlip(),\n",
    "                                                  torchvision.transforms.ToTensor(), normalize_MNIST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MNIST = torchvision.datasets.MNIST('./data/MNIST/', train=True,\n",
    "                                         transform=transform_MNIST, target_transform=None, download=False)\n",
    "test_MNIST = torchvision.datasets.MNIST('./data/MNIST/', train=False,\n",
    "                                            transform=transform_MNIST, target_transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.as_tensor(train_MNIST.targets) != torch.tensor(0)\n",
    "dset_train = (torch.utils.data.dataset.Subset(train_MNIST, np.where(idx != 0)[0]))\n",
    "dset_train_anomalous = torch.utils.data.dataset.Subset(train_MNIST, np.where(idx == 0)[0])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dset_train, batch_size=1, shuffle=True)\n",
    "print (len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.as_tensor(test_MNIST.targets) != torch.tensor(0)\n",
    "dset_test = torch.utils.data.dataset.Subset(test_MNIST, np.where(idx != 0)[0])\n",
    "dset_test_anomalous = torch.utils.data.dataset.Subset(test_MNIST, np.where(idx == 0)[0])\n",
    "testloader_normal = torch.utils.data.DataLoader(dset_test, batch_size=1, shuffle=True)\n",
    "testloader_anomalous = torch.utils.data.ConcatDataset([dset_train_anomalous, dset_test_anomalous])\n",
    "testloader_anomalous = torch.utils.data.DataLoader(testloader_anomalous, batch_size=1, shuffle=True)\n",
    "print (len(testloader_normal))\n",
    "print (len(testloader_anomalous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_BCElogit_criterion = nn.BCEWithLogitsLoss()\n",
    "dis_criterion = nn.CrossEntropyLoss()\n",
    "aen_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = model.Encoder_MNIST(latent_size_MNIST)\n",
    "gen = model.Generator_MNIST(latent_size_MNIST)\n",
    "dis_xz = model.Discriminator_xz_MNIST(latent_size_MNIST, 0.2)\n",
    "dis_xx = model.Discriminator_xx_MNIST(latent_size_MNIST, 0.2)\n",
    "dis_zz = model.Discriminator_zz_MNIST(latent_size_MNIST, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.load_state_dict(torch.load('./models/MNIST/Gaussian/1/MNIST10epochs2020-03-24-23-34-04G'))\n",
    "enc.load_state_dict(torch.load('./models/MNIST/Gaussian/1/MNIST10epochs2020-03-24-23-34-04E'))\n",
    "dis_xz.load_state_dict(torch.load('./models/MNIST/Gaussian/1/MNIST10epochs2020-03-24-23-34-04D_xz'))\n",
    "dis_xx.load_state_dict(torch.load('./models/MNIST/Gaussian/1/MNIST10epochs2020-03-24-23-34-04D_xx'))\n",
    "dis_zz.load_state_dict(torch.load('./models/MNIST/Gaussian/1/MNIST10epochs2020-03-24-23-34-04D_zz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_xz.to(device)\n",
    "dis_xx.to(device)\n",
    "dis_zz.to(device)\n",
    "enc.to(device)\n",
    "gen.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.1\n",
    "loss_neg = torch.zeros((len(testloader_normal),1)).cuda()\n",
    "loss_pos = torch.zeros((len(testloader_anomalous),1)).cuda()\n",
    "c_neg = c_pos = 0\n",
    "for step, (images, labels) in enumerate(testloader_normal, 0):\n",
    "    dis_xz.eval()\n",
    "    dis_xx.eval()\n",
    "    dis_zz.eval()\n",
    "    enc.eval()\n",
    "    gen.eval()\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size_MNIST, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "\n",
    "    loss_neg[c_neg] = feature_loss.detach()\n",
    "    c_neg += 1\n",
    "\n",
    "for step, (images, labels) in enumerate(testloader_anomalous, 0):\n",
    "    dis_xz.eval()\n",
    "    dis_xx.eval()\n",
    "    dis_zz.eval()\n",
    "    enc.eval()\n",
    "    gen.eval()\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size_MNIST, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    loss_pos[c_pos] = feature_loss.detach()\n",
    "    c_pos += 1\n",
    "\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x1 = loss_neg.cpu().numpy()\n",
    "x2 = loss_pos.cpu().numpy()\n",
    "sns.distplot(x1, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Normal')\n",
    "sns.distplot(x2, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Anomalous')\n",
    "plt.title('Distribution of normal and abnormal samples')\n",
    "plt.xlabel('Anomaly Score');\n",
    "\n",
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 50:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 50:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[lam] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print ('AUC', auc)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.2f)' % auc)\n",
    "plt.plot([0.0, 1.0], color='navy', linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ids, (images, labels) in enumerate(testloader_anomalous):\n",
    "    print (images[0].shape)\n",
    "    plt.imshow(images[0].squeeze(0), cmap='gray_r')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ids, (images, labels) in enumerate(testloader_normal):\n",
    "    print (images[0].shape)\n",
    "    plt.imshow(images[0].squeeze(0), cmap='gray_r')\n",
    "    plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

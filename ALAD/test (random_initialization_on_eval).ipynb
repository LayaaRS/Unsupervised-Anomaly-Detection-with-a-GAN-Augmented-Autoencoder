{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import modules\n",
    "from utils import dataset\n",
    "from modules import model\n",
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((256,256)),\n",
    "                                torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                torchvision.transforms.RandomVerticalFlip(),\n",
    "                                torchvision.transforms.RandomCrop(220),\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                normalize])\n",
    "norm_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), normalize])\n",
    "test_transform = torchvision.transforms.Compose([torchvision.transforms.Resize((256,256)),\n",
    "                                torchvision.transforms.RandomCrop(220),\n",
    "                                torchvision.transforms.ToTensor(),\n",
    "                                normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset.ImageFolderPaths('./data/Leukemia/train', transform = transform)\n",
    "test_data = dataset.ImageFolderPaths('./data/Leukemia/test/', transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(training_data,\n",
    "                                          batch_size= 16,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers= 0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                          batch_size= 1,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "num_epochs = 1000\n",
    "latent_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_BCElogit_criterion = nn.BCEWithLogitsLoss()\n",
    "dis_criterion = nn.CrossEntropyLoss()\n",
    "aen_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = model.Encoder_Leukemia(latent_size)\n",
    "gen = model.Generator_Leukemia(latent_size)\n",
    "dis_xz = model.Discriminator_xz_Leukemia(latent_size, 0.2)\n",
    "dis_xx = model.Discriminator_xx_Leukemia(latent_size, 0.2)\n",
    "dis_zz = model.Discriminator_zz_Leukemia(latent_size, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_lam = {}\n",
    "auroc = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random seed 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/0/Leukemia1000epochs2020-03-30-13-40-38G'))\n",
    "enc.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/0/Leukemia1000epochs2020-03-30-13-40-38E'))\n",
    "dis_xz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/0/Leukemia1000epochs2020-03-30-13-40-38D_xz'))\n",
    "dis_xx.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/0/Leukemia1000epochs2020-03-30-13-40-38D_xx'))\n",
    "dis_zz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/0/Leukemia1000epochs2020-03-30-13-40-38D_zz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_xz.to(device)\n",
    "dis_xx.to(device)\n",
    "dis_zz.to(device)\n",
    "enc.to(device)\n",
    "gen.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_xz.eval()\n",
    "dis_xx.eval()\n",
    "dis_zz.eval()\n",
    "enc.eval()\n",
    "gen.eval()\n",
    "\n",
    "loss_neg = torch.zeros((5,1)).cuda()\n",
    "loss_pos = torch.zeros((15,1)).cuda()\n",
    "c_neg = c_pos = 0\n",
    "c_neg_val = c_pos_val = cntr = 0\n",
    "for step, (images, labels, path) in enumerate(test_loader, 0):\n",
    "    if '0.tif' in str(path):\n",
    "        if c_neg_val < 5:\n",
    "            images = images.view(-1, 3, 220, 220)\n",
    "            c_neg_val += 1\n",
    "            cntr += 1\n",
    "        else:\n",
    "            break\n",
    "    elif '1.tif' in str(path):\n",
    "        if c_pos_val < 15:\n",
    "            images = images.view(-1, 3, 220, 220)\n",
    "            c_pos_val += 1\n",
    "            cntr += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    if '0.tif' in str(path):\n",
    "        loss_neg[c_neg] = feature_loss.detach()\n",
    "        c_neg += 1\n",
    "    else:\n",
    "        loss_pos[c_pos] = feature_loss.detach()\n",
    "        c_pos += 1\n",
    "\n",
    "    if cntr == 20:\n",
    "        break\n",
    "mean_neg = torch.mean(loss_neg)\n",
    "mean_pos = torch.mean(loss_pos)\n",
    "total_mean = (mean_neg + mean_pos) / 2\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))\n",
    "print ('threshold: %0.4f' %(total_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lam = 0.1\n",
    "seed = 0\n",
    "loss_neg = torch.zeros((30,1)).cuda()\n",
    "loss_pos = torch.zeros((130,1)).cuda()\n",
    "c_loss = c_neg = c_pos = 0\n",
    "for step, (images, labels, path) in enumerate(test_loader, 0):\n",
    "    images = images.view(-1, 3, 220, 220)\n",
    "    dis_xz.eval()\n",
    "    dis_xx.eval()\n",
    "    dis_zz.eval()\n",
    "    enc.eval()\n",
    "    gen.eval()\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    if '0.tif' in str(path):\n",
    "        loss_neg[c_neg] = feature_loss.detach()\n",
    "        c_neg += 1\n",
    "    else:\n",
    "        loss_pos[c_pos] = feature_loss.detach()\n",
    "        c_pos += 1\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = loss_neg.cpu().numpy()\n",
    "x2 = loss_pos.cpu().numpy()\n",
    "sns.distplot(x1, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Normal')\n",
    "sns.distplot(x2, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Anomalous')\n",
    "plt.title('Distribution of normal and abnormal samples')\n",
    "plt.xlabel('Anomaly Score');\n",
    "\n",
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 500:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 500:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[seed] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auroc[seed] = auc\n",
    "print ('AUC', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random seed 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/10/Leukemia1000epochs2020-03-15-17-59-22G'))\n",
    "enc.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/10/Leukemia1000epochs2020-03-15-17-59-22E'))\n",
    "dis_xz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/10/Leukemia1000epochs2020-03-15-17-59-22D_xz'))\n",
    "dis_xx.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/10/Leukemia1000epochs2020-03-15-17-59-22D_xx'))\n",
    "dis_zz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/10/Leukemia1000epochs2020-03-15-17-59-22D_zz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_xz.to(device)\n",
    "dis_xx.to(device)\n",
    "dis_zz.to(device)\n",
    "enc.to(device)\n",
    "gen.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_xz.eval()\n",
    "dis_xx.eval()\n",
    "dis_zz.eval()\n",
    "enc.eval()\n",
    "gen.eval()\n",
    "\n",
    "loss_neg = torch.zeros((5,1)).cuda()\n",
    "loss_pos = torch.zeros((15,1)).cuda()\n",
    "c_neg = c_pos = 0\n",
    "c_neg_val = c_pos_val = cntr = 0\n",
    "for step, (images, labels, path) in enumerate(test_loader, 0):\n",
    "    if '0.tif' in str(path):\n",
    "        if c_neg_val < 5:\n",
    "            images = images.view(-1, 3, 220, 220)\n",
    "            c_neg_val += 1\n",
    "            cntr += 1\n",
    "        else:\n",
    "            break\n",
    "    elif '1.tif' in str(path):\n",
    "        if c_pos_val < 15:\n",
    "            images = images.view(-1, 3, 220, 220)\n",
    "            c_pos_val += 1\n",
    "            cntr += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    if '0.tif' in str(path):\n",
    "        loss_neg[c_neg] = feature_loss.detach()\n",
    "        c_neg += 1\n",
    "    else:\n",
    "        loss_pos[c_pos] = feature_loss.detach()\n",
    "        c_pos += 1\n",
    "\n",
    "    if cntr == 20:\n",
    "        break\n",
    "mean_neg = torch.mean(loss_neg)\n",
    "mean_pos = torch.mean(loss_pos)\n",
    "total_mean = (mean_neg + mean_pos) / 2\n",
    "print ('model 1')\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))\n",
    "print ('threshold: %0.4f' %(total_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.1\n",
    "seed = 10\n",
    "loss_neg = torch.zeros((100,1)).cuda()\n",
    "loss_pos = torch.zeros((130,1)).cuda()\n",
    "c_loss = c_neg = c_pos = 0\n",
    "for step, (images, labels, path) in enumerate(test_loader, 0):\n",
    "    images = images.view(-1, 3, 220, 220)\n",
    "    dis_xz.eval()\n",
    "    dis_xx.eval()\n",
    "    dis_zz.eval()\n",
    "    enc.eval()\n",
    "    gen.eval()\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    if '0.tif' in str(path):\n",
    "        loss_neg[c_neg] = feature_loss.detach()\n",
    "        c_neg += 1\n",
    "        c_loss += 1\n",
    "    else:\n",
    "        loss_pos[c_pos] = feature_loss.detach()\n",
    "        c_pos += 1\n",
    "        c_loss += 1\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 1100:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 1100:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[seed] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auroc[seed] = auc\n",
    "print ('AUC', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random seed 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/100/Leukemia1000epochs2020-03-15-19-13-28G'))\n",
    "enc.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/100/Leukemia1000epochs2020-03-15-19-13-28E'))\n",
    "dis_xz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/100/Leukemia1000epochs2020-03-15-19-13-28D_xz'))\n",
    "dis_xx.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/100/Leukemia1000epochs2020-03-15-19-13-28D_xx'))\n",
    "dis_zz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/100/Leukemia1000epochs2020-03-15-19-13-28D_zz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_xz.to(device)\n",
    "dis_xx.to(device)\n",
    "dis_zz.to(device)\n",
    "enc.to(device)\n",
    "gen.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_xz.eval()\n",
    "dis_xx.eval()\n",
    "dis_zz.eval()\n",
    "enc.eval()\n",
    "gen.eval()\n",
    "\n",
    "loss_neg = torch.zeros((5,1)).cuda()\n",
    "loss_pos = torch.zeros((15,1)).cuda()\n",
    "c_neg = c_pos = 0\n",
    "c_neg_val = c_pos_val = cntr = 0\n",
    "for step, (images, labels, path) in enumerate(test_loader, 0):\n",
    "    if '0.tif' in str(path):\n",
    "        if c_neg_val < 5:\n",
    "            images = images.view(-1, 3, 220, 220)\n",
    "            c_neg_val += 1\n",
    "            cntr += 1\n",
    "        else:\n",
    "            break\n",
    "    elif '1.tif' in str(path):\n",
    "        if c_pos_val < 15:\n",
    "            images = images.view(-1, 3, 220, 220)\n",
    "            c_pos_val += 1\n",
    "            cntr += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    if '0.tif' in str(path):\n",
    "        loss_neg[c_neg] = feature_loss.detach()\n",
    "        c_neg += 1\n",
    "    else:\n",
    "        loss_pos[c_pos] = feature_loss.detach()\n",
    "        c_pos += 1\n",
    "\n",
    "    if cntr == 20:\n",
    "        break\n",
    "mean_neg = torch.mean(loss_neg)\n",
    "mean_pos = torch.mean(loss_pos)\n",
    "total_mean = (mean_neg + mean_pos) / 2\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))\n",
    "print ('threshold: %0.4f' %(total_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.1\n",
    "seed = 100\n",
    "loss_neg = torch.zeros((100,1)).cuda()\n",
    "loss_pos = torch.zeros((130,1)).cuda()\n",
    "c_loss = c_neg = c_pos = 0\n",
    "for step, (images, labels, path) in enumerate(test_loader, 0):\n",
    "    images = images.view(-1, 3, 220, 220)\n",
    "    dis_xz.eval()\n",
    "    dis_xx.eval()\n",
    "    dis_zz.eval()\n",
    "    enc.eval()\n",
    "    gen.eval()\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    if '0.tif' in str(path):\n",
    "        loss_neg[c_neg] = feature_loss.detach()\n",
    "        c_neg += 1\n",
    "        c_loss += 1\n",
    "    else:\n",
    "        loss_pos[c_pos] = feature_loss.detach()\n",
    "        c_pos += 1\n",
    "        c_loss += 1\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 1900:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 1900:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[seed] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auroc[seed] = auc\n",
    "print ('AUC', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with new loos and betha = 0.01\n",
    "sen = [0.2154, 1.0000, 1.0000]\n",
    "spe = [0.8333, 0.7200, 0.7000]\n",
    "f1 = [0.3436, 0.9028, 0.8966]\n",
    "acc = [0.3313, 0.8783, 0.8696]\n",
    "auc = [0.6692, 0.8416, 0.7868]\n",
    "\n",
    "sen_mean = np.mean(sen)\n",
    "sen_std = np.std(sen)\n",
    "\n",
    "spe_mean = np.mean(spe)\n",
    "spe_std = np.std(spe)\n",
    "\n",
    "f1_mean = np.mean(f1)\n",
    "f1_std = np.std(f1)\n",
    "\n",
    "acc_mean = np.mean(acc)\n",
    "acc_std = np.std(acc)\n",
    "\n",
    "auc_mean = np.mean(auc)\n",
    "auc_std = np.std(auc)\n",
    "\n",
    "\n",
    "print (sen_mean, sen_std)\n",
    "print (spe_mean, spe_std)\n",
    "print (f1_mean, f1_std)\n",
    "print (acc_mean, acc_std)\n",
    "print (auc_mean, auc_std)\n",
    "\n",
    "# precision: 0.84848, recall: 0.21538, specificity: 0.83333, f1: 0.34356, fp_rate: 0.16667, accuracy: 0.33125\n",
    "# AUC 0.6692307692307693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (acc_lam)\n",
    "print (auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/Leukemia/RandomSeedTest/acc_seed.txt', 'w', newline='\\n')as f:\n",
    "    f.write(str(acc_lam))\n",
    "with open('./models/Leukemia/RandomSeedTest/auroc_seed.txt', 'w', newline='\\n')as f:\n",
    "    f.write(str(auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print ('Model 1')\n",
    "gen.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/0/Leukemia1000epochs2020-03-15-12-25-32G'))\n",
    "enc.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/0/Leukemia1000epochs2020-03-15-12-25-32E'))\n",
    "dis_xz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/0/Leukemia1000epochs2020-03-15-12-25-32D_xz'))\n",
    "dis_xx.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/0/Leukemia1000epochs2020-03-15-12-25-32D_xx'))\n",
    "dis_zz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/0/Leukemia1000epochs2020-03-15-12-25-32D_zz'))\n",
    "\n",
    "dis_xz.to(device)\n",
    "dis_xx.to(device)\n",
    "dis_zz.to(device)\n",
    "enc.to(device)\n",
    "gen.to(device);\n",
    "\n",
    "start_time = time.time()\n",
    "lam = 0.1\n",
    "seed = 0\n",
    "loss_neg = torch.zeros((100,1)).cuda()\n",
    "loss_pos = torch.zeros((130,1)).cuda()\n",
    "c_loss = c_neg = c_pos = 0\n",
    "for step, (images, labels, path) in enumerate(test_loader, 0):\n",
    "    images = images.view(-1, 3, 220, 220)\n",
    "    dis_xz.eval()\n",
    "    dis_xx.eval()\n",
    "    dis_zz.eval()\n",
    "    enc.eval()\n",
    "    gen.eval()\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    if '0.tif' in str(path):\n",
    "        loss_neg[c_neg] = feature_loss.detach()\n",
    "        c_neg += 1\n",
    "        c_loss += 1\n",
    "    else:\n",
    "        loss_pos[c_pos] = feature_loss.detach()\n",
    "        c_pos += 1\n",
    "        c_loss += 1\n",
    "# print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "# print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "print ('time:', end_time)\n",
    "\n",
    "x1 = loss_neg.cpu().numpy()\n",
    "x2 = loss_pos.cpu().numpy()\n",
    "\n",
    "\n",
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 4100:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 4100:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[seed] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr_model1, tpr_model1, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "auc_model1 = metrics.auc(fpr_model1, tpr_model1)\n",
    "auroc[seed] = auc_model1\n",
    "print ('AUC', auc_model1)\n",
    "\n",
    "\n",
    "print ('Model 2')\n",
    "gen.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/10/Leukemia1000epochs2020-03-15-17-59-22G'))\n",
    "enc.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/10/Leukemia1000epochs2020-03-15-17-59-22E'))\n",
    "dis_xz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/10/Leukemia1000epochs2020-03-15-17-59-22D_xz'))\n",
    "dis_xx.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/10/Leukemia1000epochs2020-03-15-17-59-22D_xx'))\n",
    "dis_zz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/10/Leukemia1000epochs2020-03-15-17-59-22D_zz'))\n",
    "\n",
    "dis_xz.to(device)\n",
    "dis_xx.to(device)\n",
    "dis_zz.to(device)\n",
    "enc.to(device)\n",
    "gen.to(device);\n",
    "\n",
    "start_time = time.time()\n",
    "lam = 0.1\n",
    "seed = 10\n",
    "loss_neg = torch.zeros((100,1)).cuda()\n",
    "loss_pos = torch.zeros((130,1)).cuda()\n",
    "c_loss = c_neg = c_pos = 0\n",
    "for step, (images, labels, path) in enumerate(test_loader, 0):\n",
    "    images = images.view(-1, 3, 220, 220)\n",
    "    dis_xz.eval()\n",
    "    dis_xx.eval()\n",
    "    dis_zz.eval()\n",
    "    enc.eval()\n",
    "    gen.eval()\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    if '0.tif' in str(path):\n",
    "        loss_neg[c_neg] = feature_loss.detach()\n",
    "        c_neg += 1\n",
    "        c_loss += 1\n",
    "    else:\n",
    "        loss_pos[c_pos] = feature_loss.detach()\n",
    "        c_pos += 1\n",
    "        c_loss += 1\n",
    "# print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "# print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "print ('time:', end_time)\n",
    "\n",
    "x1 = loss_neg.cpu().numpy()\n",
    "x2 = loss_pos.cpu().numpy()\n",
    "\n",
    "\n",
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 1200:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 1200:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[seed] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr_model2, tpr_model2, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "auc_model2 = metrics.auc(fpr_model2, tpr_model2)\n",
    "auroc[seed] = auc_model2\n",
    "print ('AUC', auc_model2)\n",
    "\n",
    "\n",
    "print ('Model 3')\n",
    "gen.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/100/Leukemia1000epochs2020-03-15-19-13-28G'))\n",
    "enc.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/100/Leukemia1000epochs2020-03-15-19-13-28E'))\n",
    "dis_xz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/100/Leukemia1000epochs2020-03-15-19-13-28D_xz'))\n",
    "dis_xx.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/100/Leukemia1000epochs2020-03-15-19-13-28D_xx'))\n",
    "dis_zz.load_state_dict(torch.load('./models/Leukemia/RandomSeedTest/100/Leukemia1000epochs2020-03-15-19-13-28D_zz'))\n",
    "\n",
    "dis_xz.to(device)\n",
    "dis_xx.to(device)\n",
    "dis_zz.to(device)\n",
    "enc.to(device)\n",
    "gen.to(device);\n",
    "\n",
    "start_time = time.time()\n",
    "lam = 0.1\n",
    "seed = 100\n",
    "loss_neg = torch.zeros((100,1)).cuda()\n",
    "loss_pos = torch.zeros((130,1)).cuda()\n",
    "c_loss = c_neg = c_pos = 0\n",
    "for step, (images, labels, path) in enumerate(test_loader, 0):\n",
    "    images = images.view(-1, 3, 220, 220)\n",
    "    dis_xz.eval()\n",
    "    dis_xx.eval()\n",
    "    dis_zz.eval()\n",
    "    enc.eval()\n",
    "    gen.eval()\n",
    "    \n",
    "    x_real_test = images.cuda()\n",
    "    z_random = torch.randn(images.shape[0], latent_size, 1, 1).cuda()\n",
    "    z_gen = enc(x_real_test)\n",
    "    x_gen = gen(z_random)\n",
    "    rec_x = gen(z_gen)\n",
    "    rec_z = enc(x_gen)\n",
    "    \n",
    "    l_gen, _ = dis_xz(x_real_test, z_gen)\n",
    "    l_enc, _ = dis_xz(x_gen, z_random)\n",
    "    \n",
    "    x_logit_real, inter_layer_inp = dis_xx(x_real_test, x_real_test)\n",
    "    x_logit_fake, inter_layer_rct = dis_xx(x_real_test, rec_x)\n",
    "   \n",
    "    fm = inter_layer_inp - inter_layer_rct\n",
    "    feature_loss = torch.norm(fm, 1, keepdim=False) \n",
    "    feature_loss = feature_loss.squeeze()\n",
    "    \n",
    "    if '0.tif' in str(path):\n",
    "        loss_neg[c_neg] = feature_loss.detach()\n",
    "        c_neg += 1\n",
    "        c_loss += 1\n",
    "    else:\n",
    "        loss_pos[c_pos] = feature_loss.detach()\n",
    "        c_pos += 1\n",
    "        c_loss += 1\n",
    "# print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "# print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))\n",
    "\n",
    "end_time = time.time() - start_time\n",
    "print ('time:', end_time)\n",
    "\n",
    "x1 = loss_neg.cpu().numpy()\n",
    "x2 = loss_pos.cpu().numpy()\n",
    "\n",
    "\n",
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 2720:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 2720:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[seed] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr_model3, tpr_model3, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "auc_model3 = metrics.auc(fpr_model3, tpr_model3)\n",
    "auroc[seed] = auc_model3\n",
    "print ('AUC', auc_model3)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_model1, tpr_model1, color='darkorange', label='Model 1(area = %0.3f)' % auc_model1)\n",
    "plt.plot(fpr_model2, tpr_model2, color='green', label='Model 2(area = %0.3f)' % auc_model2)\n",
    "plt.plot(fpr_model3, tpr_model3, color='red', label='Model 3(area = %0.3f)' % auc_model3)\n",
    "plt.plot([0.0, 1.0], color='navy', linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = sorted(acc_lam.items())\n",
    "x, y = zip(*lists)\n",
    "plt.plot(x, y, color='darkorange')\n",
    "plt.xlabel('Random Initialization')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('The accuracy of ALAD model for different random initialization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = [0.7390, 0.8857, 0.7950]\n",
    "\n",
    "auc_mean = np.mean(auc)\n",
    "auc_std = np.std(auc)\n",
    "\n",
    "print (auc_mean, auc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = [0.9692, 0.9385, 0.9307]\n",
    "spe = [0.7000, 0.8300, 0.7200]\n",
    "f1 = [0.8811, 0.9071, 0.8674]\n",
    "acc = [0.8522, 0.8913, 0.8391]\n",
    "auc = [0.7480, 0.8634, 0.7850]\n",
    "\n",
    "sen_mean = np.mean(sen)\n",
    "sen_std = np.std(sen)\n",
    "\n",
    "spe_mean = np.mean(spe)\n",
    "spe_std = np.std(spe)\n",
    "\n",
    "f1_mean = np.mean(f1)\n",
    "f1_std = np.std(f1)\n",
    "\n",
    "acc_mean = np.mean(acc)\n",
    "acc_std = np.std(acc)\n",
    "\n",
    "auc_mean = np.mean(auc)\n",
    "auc_std = np.std(auc)\n",
    "\n",
    "\n",
    "print (sen_mean, sen_std)\n",
    "print (spe_mean, spe_std)\n",
    "print (f1_mean, f1_std)\n",
    "print (acc_mean, acc_std)\n",
    "print (auc_mean, auc_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laya/anaconda3/envs/t13/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import argparse\n",
    "import datetime\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import modules\n",
    "from utils import dataset\n",
    "from imp import reload\n",
    "from modules import encoder_CIFAR10, generator_CIFAR10, discriminator_CIFAR10\n",
    "from modules import encoder_MNIST, generator_MNIST, discriminator_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "num_epochs = 500\n",
    "latent_size_CIFAR10 = 100\n",
    "latent_size_MNIST = 100\n",
    "acc_lam = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_CIFAR10 = torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "norm_transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), normalize_CIFAR10])\n",
    "transform_CIFAR10 = torchvision.transforms.Compose([torchvision.transforms.Resize((35,35)),\n",
    "                                torchvision.transforms.FiveCrop(32),\n",
    "                                torchvision.transforms.Lambda(lambda crops: torch.stack([norm_transform(crop)\n",
    "                                for crop in crops]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CIFAR10 = torchvision.datasets.CIFAR10('./data/CIFAR10/', train=True, \n",
    "                                            transform=transform_CIFAR10, target_transform=None, download=False)\n",
    "test_CIFAR10 = torchvision.datasets.CIFAR10('./data/CIFAR10/', train=False, \n",
    "                                            transform=transform_CIFAR10, target_transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.tensor(train_CIFAR10.targets) == torch.tensor(0)\n",
    "dset_train = torch.utils.data.dataset.Subset(train_CIFAR10, np.where(idx==True)[0])\n",
    "dset_train_anomalous = torch.utils.data.dataset.Subset(train_CIFAR10, np.where(idx==False)[0])\n",
    "trainloader = torch.utils.data.DataLoader(dset_train, batch_size=1, shuffle=True)\n",
    "print (len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = torch.tensor(test_CIFAR10.targets) == torch.tensor(0)\n",
    "dset_test = torch.utils.data.dataset.Subset(test_CIFAR10, np.where(idx==True)[0])\n",
    "dset_test_anomalous = torch.utils.data.dataset.Subset(test_CIFAR10, np.where(idx==False)[0])\n",
    "testloader_normal = torch.utils.data.DataLoader(dset_test, batch_size=1, shuffle=True)\n",
    "testloader_anomalous = torch.utils.data.ConcatDataset([dset_train_anomalous, dset_test_anomalous])\n",
    "testloader_anomalous = torch.utils.data.DataLoader(testloader_anomalous, batch_size=1, shuffle=True)\n",
    "print (len(testloader_normal), len(testloader_anomalous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_criterion = nn.CrossEntropyLoss()\n",
    "aen_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoder_CIFAR10.Encoder(latent_size_CIFAR10)\n",
    "gen = generator_CIFAR10.Generator(latent_size_CIFAR10)\n",
    "dis = discriminator_CIFAR10.Discriminator(latent_size_CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.load_state_dict(torch.load('./models/CIFAR10/ALAD_way/8/CIFAR1025epochs2020-03-26-15-11-30G'))\n",
    "enc.load_state_dict(torch.load('./models/CIFAR10/ALAD_way/8/CIFAR1025epochs2020-03-26-15-11-30E'))\n",
    "dis.load_state_dict(torch.load('./models/CIFAR10/ALAD_way/8/CIFAR1025epochs2020-03-26-15-11-30D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis.to(device)\n",
    "enc.to(device)\n",
    "gen.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.2\n",
    "betha = 1\n",
    "loss_neg = torch.zeros((len(testloader_normal),1)).cuda()\n",
    "loss_pos = torch.zeros((len(testloader_anomalous),1)).cuda()\n",
    "\n",
    "c_neg = c_pos = 0\n",
    "for step, (images, labels) in enumerate(testloader_normal, 0):\n",
    "    images = images.view(-1, 3, 32, 32)\n",
    "    dis.eval()\n",
    "    gen.eval()\n",
    "    enc.eval()\n",
    "    x_real_test = images.cuda()\n",
    "    E_x = enc(x_real_test)\n",
    "    G_z = gen(E_x)\n",
    "    \n",
    "    E_G_z = enc(G_z)\n",
    "    \n",
    "    real, internal_real = dis(x_real_test)\n",
    "    fake, internal_fake = dis(G_z)\n",
    "    \n",
    "    latentloss = torch.mean(torch.abs(E_x - E_G_z))\n",
    "    resloss = torch.mean(torch.abs(x_real_test - G_z))\n",
    "    discloss = torch.mean(torch.abs(internal_real-internal_fake))\n",
    "    loss_test = (1 - lam) * resloss + lam * discloss + betha * latentloss\n",
    "    loss_neg[c_neg] = loss_test.detach()\n",
    "    c_neg += 1\n",
    "    \n",
    "for step, (images, labels) in enumerate(testloader_anomalous, 0):\n",
    "    images = images.view(-1, 3, 32, 32)\n",
    "    dis.eval()\n",
    "    gen.eval()\n",
    "    enc.eval()\n",
    "    x_real_test = images.cuda()\n",
    "    E_x = enc(x_real_test)\n",
    "    G_z = gen(E_x)\n",
    "    \n",
    "    E_G_z = enc(G_z)\n",
    "    \n",
    "    real, internal_real = dis(x_real_test)\n",
    "    fake, internal_fake = dis(G_z)\n",
    "    \n",
    "    latentloss = torch.mean(torch.abs(E_x - E_G_z))\n",
    "    resloss = torch.mean(torch.abs(x_real_test - G_z))\n",
    "    discloss = torch.mean(torch.abs(internal_real-internal_fake))\n",
    "    loss_test = (1 - lam) * resloss + lam * discloss + betha * latentloss\n",
    "    loss_pos[c_pos] = loss_test.detach()\n",
    "    c_pos += 1\n",
    "\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1 = loss_neg.cpu().numpy()\n",
    "x2 = loss_pos.cpu().numpy()\n",
    "sns.distplot(x1, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Normal')\n",
    "sns.distplot(x2, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Anomalous')\n",
    "plt.title('Distribution of normal and abnormal samples')\n",
    "plt.xlabel('Anomaly Score');\n",
    "\n",
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 0.08:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 0.08:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[lam] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "prec, rec, _ = metrics.precision_recall_curve(y.cpu(), scores.cpu())\n",
    "average_precision = metrics.average_precision_score(y.cpu(), scores.cpu())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print ('AUC', auc)\n",
    "print ('average precision :', average_precision)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % auc)\n",
    "plt.plot([0.0, 1.0], color='navy', linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_MNIST = torchvision.transforms.Normalize((0.5, ), (0.5, ))\n",
    "transform_MNIST = torchvision.transforms.Compose([torchvision.transforms.Resize((33, 33)),\n",
    "                                                torchvision.transforms.RandomVerticalFlip(),\n",
    "                                                torchvision.transforms.RandomCrop(28),\n",
    "                                                torchvision.transforms.ToTensor(),\n",
    "                                                normalize_MNIST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MNIST = torchvision.datasets.MNIST('./data/MNIST/', train=True,\n",
    "                                         transform=transform_MNIST, target_transform=None, download=False)\n",
    "test_MNIST = torchvision.datasets.MNIST('./data/MNIST/', train=False,\n",
    "                                            transform=transform_MNIST, target_transform=None, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.as_tensor(train_MNIST.targets) == torch.tensor(0)\n",
    "dset_train = (torch.utils.data.dataset.Subset(train_MNIST, np.where(idx != 0)[0]))\n",
    "dset_train_anomalous = torch.utils.data.dataset.Subset(train_MNIST, np.where(idx == 0)[0])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dset_train, batch_size=1, shuffle=True)\n",
    "print (len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.as_tensor(test_MNIST.targets) == torch.tensor(0)\n",
    "dset_test = torch.utils.data.dataset.Subset(test_MNIST, np.where(idx != 0)[0])\n",
    "dset_test_anomalous = torch.utils.data.dataset.Subset(test_MNIST, np.where(idx == 0)[0])\n",
    "testloader_normal = torch.utils.data.DataLoader(dset_test, batch_size=1, shuffle=True)\n",
    "testloader_anomalous = torch.utils.data.ConcatDataset([dset_train_anomalous, dset_test_anomalous])\n",
    "testloader_anomalous = torch.utils.data.DataLoader(testloader_anomalous, batch_size=1, shuffle=True)\n",
    "print (len(testloader_normal))\n",
    "print (len(testloader_anomalous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(encoder_MNIST)\n",
    "reload(generator_MNIST)\n",
    "reload(discriminator_MNIST)\n",
    "enc = encoder_MNIST.Encoder(latent_size_MNIST)\n",
    "gen = generator_MNIST.Generator(latent_size_MNIST)\n",
    "dis = discriminator_MNIST.Discriminator(latent_size_MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = (torch.load('./models/MNIST/Gaussian/0/MNIST50epochs2020-03-03-21-06-17G'))\n",
    "enc = (torch.load('./models/MNIST/Gaussian/0/MNIST50epochs2020-03-03-21-06-17E'))\n",
    "dis = (torch.load('./models/MNIST/Gaussian/0/MNIST50epochs2020-03-03-21-06-17D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen.load_state_dict(torch.load('./models/CIFAR10/ALAD_way/0/CIFAR1030epochs2020-03-19-11-20-27G'))\n",
    "enc.load_state_dict(torch.load('./models/CIFAR10/ALAD_way/0/CIFAR1030epochs2020-03-19-11-20-27E'))\n",
    "dis.load_state_dict(torch.load('./models/CIFAR10/ALAD_way/0/CIFAR1030epochs2020-03-19-11-20-27D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis.to(device)\n",
    "enc.to(device)\n",
    "gen.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lam = 0.1\n",
    "betha = 0.1\n",
    "loss_neg = torch.zeros((len(testloader_normal),1)).cuda()\n",
    "loss_pos = torch.zeros((len(testloader_anomalous),1)).cuda()\n",
    "c_neg = c_pos = 0\n",
    "start_time = time.time()\n",
    "for step, (images, labels) in enumerate(testloader_normal, 0):\n",
    "    images = images.view(-1, 1, 28, 28)\n",
    "    dis.eval()\n",
    "    gen.eval()\n",
    "    enc.eval()\n",
    "    x_real_test = images.cuda()\n",
    "    E_x = enc(x_real_test)\n",
    "    G_z = gen(E_x)\n",
    "    E_G_z = enc(G_z)\n",
    "    \n",
    "    real, internal_real = dis(x_real_test)\n",
    "    fake, internal_fake = dis(G_z)\n",
    "    \n",
    "    latentloss = torch.mean(torch.abs(E_x - E_G_z))\n",
    "    resloss = torch.mean(torch.abs(x_real_test - G_z))\n",
    "    discloss = torch.mean(torch.abs(internal_real-internal_fake))\n",
    "    loss_test = (1 - lam) * resloss + lam * discloss + betha * latentloss\n",
    "    loss_neg[c_neg] = loss_test.detach()\n",
    "    c_neg += 1\n",
    "\n",
    "for step, (images, labels) in enumerate(testloader_anomalous, 0):\n",
    "    images = images.view(-1, 1, 28, 28)\n",
    "    dis.eval()\n",
    "    gen.eval()\n",
    "    enc.eval()\n",
    "    x_real_test = images.cuda()\n",
    "    E_x = enc(x_real_test)\n",
    "    G_z = gen(E_x)\n",
    "    E_G_z = enc(G_z)\n",
    "    \n",
    "    real, internal_real = dis(x_real_test)\n",
    "    fake, internal_fake = dis(G_z)\n",
    "    \n",
    "    latentloss = torch.mean(torch.abs(E_x - E_G_z))\n",
    "    resloss = torch.mean(torch.abs(x_real_test - G_z))\n",
    "    discloss = torch.mean(torch.abs(internal_real-internal_fake))\n",
    "    loss_test = (1 - lam) * resloss + lam * discloss + betha * latentloss\n",
    "    loss_pos[c_pos] = loss_test.detach()\n",
    "    c_pos += 1\n",
    "end_time = time.time() - start_time\n",
    "# print ('model time: ', end_time)\n",
    "print ('mean negative: %0.4f, std negative: %0.4f' %(torch.mean(loss_neg), torch.std(loss_neg)))\n",
    "print ('mean positive: %0.4f, std positive: %0.4f' %(torch.mean(loss_pos), torch.std(loss_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x1 = loss_neg.cpu().numpy()\n",
    "x2 = loss_pos.cpu().numpy()\n",
    "sns.distplot(x1, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Normal')\n",
    "sns.distplot(x2, hist=False, kde=True, kde_kws={'linewidth': 3}, label='Anomalous')\n",
    "plt.title('Distribution of normal and abnormal samples')\n",
    "plt.xlabel('Anomaly Score');\n",
    "\n",
    "FP = TP = []\n",
    "neg_pre_wrong = 0\n",
    "for i in range(len(loss_neg)):\n",
    "    if loss_neg[i] > 0.05:\n",
    "        neg_pre_wrong += 1\n",
    "\n",
    "pos_pre_wrong = 0\n",
    "for i in range(len(loss_pos)):\n",
    "    if loss_pos[i] <= 0.05:\n",
    "        pos_pre_wrong += 1\n",
    "print (\"number of normal samples missclassified: %d, number of anomalous samples missclassified: %d\" \n",
    "       %(neg_pre_wrong, pos_pre_wrong))\n",
    "tp = (len(loss_pos) - pos_pre_wrong)\n",
    "fn = pos_pre_wrong\n",
    "fp = neg_pre_wrong\n",
    "tn = len(loss_neg) - neg_pre_wrong\n",
    "precision = tp / (tp + fp)\n",
    "## recall / sensitivity / True Positive Rate\n",
    "recall = tp / (tp + fn)\n",
    "## False Positive Rate / 1 - Specificity\n",
    "fp_rate = fp / (fp + tn)\n",
    "specificity = tn / (tn + fp)\n",
    "f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "acc_lam[lam] = accuracy\n",
    "print (\"tp: %d, fp: %d, fn: %d, tn: %d\" %(tp, fp, fn, tn))\n",
    "print (\"precision: %.5f, recall: %.5f, specificity: %.5f, f1: %.5f, fp_rate: %.5f, accuracy: %.5f\" \n",
    "       %(precision, recall, specificity, f1, fp_rate, accuracy))\n",
    "anomalous = torch.ones((len(loss_pos), 1))\n",
    "normal = torch.zeros((len(loss_neg), 1))\n",
    "y = torch.cat((anomalous, normal), 0)\n",
    "scores = torch.cat((loss_pos, loss_neg), 0)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y.cpu(), scores.cpu())\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print ('AUC', auc)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % auc)\n",
    "plt.plot([0.0, 1.0], color='navy', linestyle='--')\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([-0.01, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ids, (images, labels) in enumerate(testloader_anomalous):\n",
    "    print (images[0].shape)\n",
    "    plt.imshow(images[0].squeeze(0), cmap='gray_r')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ids, (images, labels) in enumerate(testloader_normal):\n",
    "    print (images[0].shape)\n",
    "    plt.imshow(images[0].squeeze(0), cmap='gray_r')\n",
    "    plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
